{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd7189ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/work/.local/lib/python3.10/site-packages/chromedriver_autoinstaller/126/chromedriver'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import chromedriver_autoinstaller\n",
    "from urllib.parse import unquote_plus\n",
    "\n",
    "# Automatically download and install the matching ChromeDriver\n",
    "chromedriver_autoinstaller.install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6ec9e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install selenium chromedriver_autoinstaller markdownify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b2b5614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of subjects\n",
    "subjects = [\n",
    "    \"Architecture\", \"Art+%26+Culture\", \"Biology+%26+Life+Sciences\", \"Business+%26+Management\",\n",
    "    \"Chemistry\", \"Communication\", \"Computer+Science\", \"Data+Analysis+%26+Statistics\", \"Design\",\n",
    "    \"Economics+%26+Finance\", \"Education+%26+Teacher+Training\", \"Electronics\", \"Energy+%26+Earth+Sciences\",\n",
    "    \"Engineering\", \"Environmental+Studies\", \"Ethics\", \"Food+%26+Nutrition\", \"Health+%26+Safety\", \"History\",\n",
    "    \"Humanities\", \"Language\", \"Law\", \"Literature\", \"Math\", \"Medicine\", \"Music\", \"Philanthropy\",\n",
    "    \"Philosophy+%26+Ethics\", \"Physics\", \"Science\", \"Social+Sciences\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d436ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # Run headless Chrome if needed\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.add_argument('--disable-gpu')\n",
    "chrome_options.add_argument('--remote-debugging-port=9222')\n",
    "\n",
    "# Initialize WebDriver\n",
    "driver = webdriver.Chrome(service=Service('/home/work/.local/lib/python3.10/site-packages/chromedriver_autoinstaller/126/chromedriver'), options=chrome_options)\n",
    "\n",
    "wait = WebDriverWait(driver, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb29a8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_page_number(driver):\n",
    "    time.sleep(2)  # Ensure the page has fully loaded\n",
    "    try:\n",
    "        # Find the <ul> element with class \"pagination\"\n",
    "        pagination_element = driver.find_element(By.CSS_SELECTOR, \"ul.pagination\")\n",
    "        pagination_html = pagination_element.get_attribute('outerHTML')\n",
    "        soup = BeautifulSoup(pagination_html, 'html.parser')\n",
    "        \n",
    "        page_items = soup.find_all('li', class_='page-item')\n",
    "        if len(page_items) > 1:\n",
    "            last_page_number = int(page_items[-2].text.strip())\n",
    "        else:\n",
    "            last_page_number = 1\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting pagination: {e}\")\n",
    "        last_page_number = 1\n",
    "    return last_page_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ebfe31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_course_data(driver, subject, page):\n",
    "    course_data = []\n",
    "    url = f\"https://www.edx.org/search?tab=course&page={page}&subject={subject}\"\n",
    "    driver.get(url)\n",
    "    wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'search-results-container')))\n",
    "    time.sleep(1.5)  # Ensure the page is fully loaded\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Find all course cards\n",
    "    course_cards = soup.find_all('a', class_='base-card-link')\n",
    "    if not course_cards:\n",
    "        return []\n",
    "\n",
    "    # Loop through each course link\n",
    "    for card in course_cards:\n",
    "        href = card['href']\n",
    "        course_url = \"https://www.edx.org\" + href\n",
    "        driver.get(course_url)\n",
    "        wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'course-header'))) \n",
    "        course_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "\n",
    "        # Extract course details\n",
    "        title = course_soup.find('div', class_='course-header').find('h1').text.strip()\n",
    "        rating_element = course_soup.find('div', class_='course-header').find('div', class_='h5 ml-1 mr-3 mb-0')\n",
    "        rating = rating_element.text.strip() if rating_element else None\n",
    "        sub_info_element = course_soup.find('div', class_='course-header').find('div', class_='p').find('p')\n",
    "        sub_info = sub_info_element.text.strip() if sub_info_element else None\n",
    "        image_url_element = course_soup.find('div', class_='course-header').find('img', class_='CloudflareImage')\n",
    "        image_url = image_url_element['src'] if image_url_element else None\n",
    "\n",
    "        preview_expand_components = course_soup.find('div', class_='course-main container-mw-sm container-fluid').find_all('div', class_='preview-expand-component')\n",
    "        about = ' '.join([p.text.strip() for p in preview_expand_components[0].find_all('p')]) if len(preview_expand_components) > 0 else None\n",
    "        what_you_will_learn = '. '.join([li.text.strip() for li in preview_expand_components[1].find_all('li')]) if len(preview_expand_components) > 1 else None\n",
    "        syllabus = ' '.join([p.text.strip() for p in preview_expand_components[2].find_all('p')]) if len(preview_expand_components) > 2 else None\n",
    "\n",
    "       # Extract institution, subject, level, and language information\n",
    "        info_elements = course_soup.find('div', class_='course-main container-mw-sm container-fluid').find('ul', class_='mb-0 pl-3 ml-1').find_all('li')\n",
    "\n",
    "        #Sometime a some time p \n",
    "        institution_elem = info_elements[0].find('a') or info_elements[0].find('p')\n",
    "\n",
    "        institution = institution_elem.text.strip() if institution_elem else None\n",
    "        subject = info_elements[1].find('a').text.strip() if len(info_elements) > 1 else None\n",
    "        level = info_elements[2].text.strip().replace('Level: ', '') if len(info_elements) > 2 else None\n",
    "        \n",
    "        language_element = course_soup.find('div', class_='course-main container-mw-sm container-fluid').find_all('div', class_='col-12 col-md-6')[1].find('ul', class_='pl-3 ml-1 mb-0').find_all('li')[0]\n",
    "        language = language_element.text.strip().replace('Language: ', '') if language_element else None\n",
    "\n",
    "        course_data.append({\n",
    "            'title': title,\n",
    "            'sub_info': sub_info,\n",
    "            'rating': rating,\n",
    "            'subject': subject,\n",
    "            'level': level,\n",
    "            'language': language,\n",
    "            'institution': institution,\n",
    "            'about': about,\n",
    "            'what_you_will_learn': what_you_will_learn,\n",
    "            'syllabus': syllabus,\n",
    "            'image_url': image_url,\n",
    "            'course_url': course_url\n",
    "        })\n",
    "    return course_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46ba2d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Architecture\n",
      "Last page number for subject Architecture: 4\n",
      "Fetching page 1 for subject Architecture, count: 24\n",
      "Fetching page 2 for subject Architecture, count: 24\n",
      "Fetching page 3 for subject Architecture, count: 24\n",
      "Fetching page 4 for subject Architecture, count: 1\n",
      "===> Total courses fetched for Architecture: 73\n",
      "Fetching Art+%26+Culture\n",
      "Last page number for subject Art+%26+Culture: 11\n",
      "Fetching page 1 for subject Art+%26+Culture, count: 24\n",
      "Fetching page 2 for subject Art+%26+Culture, count: 24\n",
      "Fetching page 3 for subject Art+%26+Culture, count: 24\n",
      "Fetching page 4 for subject Art+%26+Culture, count: 24\n",
      "Fetching page 5 for subject Art+%26+Culture, count: 24\n",
      "Fetching page 6 for subject Art+%26+Culture, count: 24\n",
      "Fetching page 7 for subject Art+%26+Culture, count: 24\n",
      "Fetching page 8 for subject Art+%26+Culture, count: 24\n",
      "Fetching page 9 for subject Art+%26+Culture, count: 24\n",
      "Fetching page 10 for subject Art+%26+Culture, count: 24\n",
      "Fetching page 11 for subject Art+%26+Culture, count: 11\n",
      "===> Total courses fetched for Art+%26+Culture: 251\n",
      "Fetching Biology+%26+Life+Sciences\n",
      "Last page number for subject Biology+%26+Life+Sciences: 12\n",
      "Fetching page 1 for subject Biology+%26+Life+Sciences, count: 24\n",
      "Fetching page 2 for subject Biology+%26+Life+Sciences, count: 24\n",
      "Fetching page 3 for subject Biology+%26+Life+Sciences, count: 24\n",
      "Fetching page 4 for subject Biology+%26+Life+Sciences, count: 24\n",
      "Fetching page 5 for subject Biology+%26+Life+Sciences, count: 24\n",
      "Fetching page 6 for subject Biology+%26+Life+Sciences, count: 24\n",
      "Fetching page 7 for subject Biology+%26+Life+Sciences, count: 24\n",
      "Fetching page 8 for subject Biology+%26+Life+Sciences, count: 24\n",
      "Fetching page 9 for subject Biology+%26+Life+Sciences, count: 24\n",
      "Fetching page 10 for subject Biology+%26+Life+Sciences, count: 24\n",
      "Fetching page 11 for subject Biology+%26+Life+Sciences, count: 24\n",
      "Fetching page 12 for subject Biology+%26+Life+Sciences, count: 8\n",
      "===> Total courses fetched for Biology+%26+Life+Sciences: 272\n",
      "Fetching Business+%26+Management\n",
      "Last page number for subject Business+%26+Management: 42\n",
      "Fetching page 1 for subject Business+%26+Management, count: 24\n",
      "Fetching page 2 for subject Business+%26+Management, count: 24\n",
      "Fetching page 3 for subject Business+%26+Management, count: 24\n",
      "Fetching page 4 for subject Business+%26+Management, count: 24\n",
      "Fetching page 5 for subject Business+%26+Management, count: 24\n",
      "Fetching page 6 for subject Business+%26+Management, count: 24\n",
      "Fetching page 7 for subject Business+%26+Management, count: 24\n",
      "Fetching page 8 for subject Business+%26+Management, count: 24\n",
      "Fetching page 9 for subject Business+%26+Management, count: 24\n",
      "Fetching page 10 for subject Business+%26+Management, count: 24\n",
      "Fetching page 11 for subject Business+%26+Management, count: 24\n",
      "Fetching page 12 for subject Business+%26+Management, count: 24\n",
      "Fetching page 13 for subject Business+%26+Management, count: 24\n",
      "Fetching page 14 for subject Business+%26+Management, count: 24\n",
      "Fetching page 15 for subject Business+%26+Management, count: 24\n",
      "Fetching page 16 for subject Business+%26+Management, count: 24\n",
      "Fetching page 17 for subject Business+%26+Management, count: 24\n",
      "Fetching page 18 for subject Business+%26+Management, count: 24\n",
      "Fetching page 19 for subject Business+%26+Management, count: 24\n",
      "Fetching page 20 for subject Business+%26+Management, count: 24\n",
      "Fetching page 21 for subject Business+%26+Management, count: 24\n",
      "Fetching page 22 for subject Business+%26+Management, count: 24\n",
      "Fetching page 23 for subject Business+%26+Management, count: 24\n",
      "Fetching page 24 for subject Business+%26+Management, count: 24\n",
      "Fetching page 25 for subject Business+%26+Management, count: 24\n",
      "Fetching page 26 for subject Business+%26+Management, count: 24\n",
      "Fetching page 27 for subject Business+%26+Management, count: 24\n",
      "Fetching page 28 for subject Business+%26+Management, count: 24\n",
      "Fetching page 29 for subject Business+%26+Management, count: 24\n",
      "Fetching page 30 for subject Business+%26+Management, count: 24\n",
      "Fetching page 31 for subject Business+%26+Management, count: 24\n",
      "Fetching page 32 for subject Business+%26+Management, count: 24\n",
      "Fetching page 33 for subject Business+%26+Management, count: 24\n",
      "Fetching page 34 for subject Business+%26+Management, count: 24\n",
      "Fetching page 35 for subject Business+%26+Management, count: 24\n",
      "Fetching page 36 for subject Business+%26+Management, count: 24\n",
      "Fetching page 37 for subject Business+%26+Management, count: 24\n",
      "Fetching page 38 for subject Business+%26+Management, count: 24\n",
      "Fetching page 39 for subject Business+%26+Management, count: 24\n",
      "Fetching page 40 for subject Business+%26+Management, count: 24\n",
      "Fetching page 41 for subject Business+%26+Management, count: 24\n",
      "Fetching page 42 for subject Business+%26+Management, count: 16\n",
      "===> Total courses fetched for Business+%26+Management: 1000\n",
      "Fetching Chemistry\n",
      "Last page number for subject Chemistry: 4\n",
      "Fetching page 1 for subject Chemistry, count: 24\n",
      "Fetching page 2 for subject Chemistry, count: 24\n",
      "Fetching page 3 for subject Chemistry, count: 24\n",
      "Fetching page 4 for subject Chemistry, count: 4\n",
      "===> Total courses fetched for Chemistry: 76\n",
      "Fetching Communication\n",
      "Last page number for subject Communication: 14\n",
      "Fetching page 1 for subject Communication, count: 24\n",
      "Fetching page 2 for subject Communication, count: 24\n",
      "Fetching page 3 for subject Communication, count: 24\n",
      "Fetching page 4 for subject Communication, count: 24\n",
      "Fetching page 5 for subject Communication, count: 24\n",
      "Fetching page 6 for subject Communication, count: 24\n",
      "Fetching page 7 for subject Communication, count: 24\n",
      "Fetching page 8 for subject Communication, count: 24\n",
      "Fetching page 9 for subject Communication, count: 24\n",
      "Fetching page 10 for subject Communication, count: 24\n",
      "Fetching page 11 for subject Communication, count: 24\n",
      "Fetching page 12 for subject Communication, count: 24\n",
      "Fetching page 13 for subject Communication, count: 24\n",
      "Fetching page 14 for subject Communication, count: 19\n",
      "===> Total courses fetched for Communication: 331\n",
      "Fetching Computer+Science\n",
      "Last page number for subject Computer+Science: 42\n",
      "Fetching page 1 for subject Computer+Science, count: 24\n",
      "Fetching page 2 for subject Computer+Science, count: 24\n",
      "Fetching page 3 for subject Computer+Science, count: 24\n",
      "Fetching page 4 for subject Computer+Science, count: 24\n",
      "Fetching page 5 for subject Computer+Science, count: 24\n",
      "Fetching page 6 for subject Computer+Science, count: 24\n",
      "Fetching page 7 for subject Computer+Science, count: 24\n",
      "Fetching page 8 for subject Computer+Science, count: 24\n",
      "Fetching page 9 for subject Computer+Science, count: 24\n",
      "Fetching page 10 for subject Computer+Science, count: 24\n",
      "Fetching page 11 for subject Computer+Science, count: 24\n",
      "Fetching page 12 for subject Computer+Science, count: 24\n",
      "Fetching page 13 for subject Computer+Science, count: 24\n",
      "Fetching page 14 for subject Computer+Science, count: 24\n",
      "Fetching page 15 for subject Computer+Science, count: 24\n",
      "Fetching page 16 for subject Computer+Science, count: 24\n",
      "Fetching page 17 for subject Computer+Science, count: 24\n",
      "Fetching page 18 for subject Computer+Science, count: 24\n",
      "Fetching page 19 for subject Computer+Science, count: 24\n",
      "Fetching page 20 for subject Computer+Science, count: 24\n",
      "Fetching page 21 for subject Computer+Science, count: 24\n",
      "Fetching page 22 for subject Computer+Science, count: 24\n",
      "Fetching page 23 for subject Computer+Science, count: 24\n",
      "Fetching page 24 for subject Computer+Science, count: 24\n",
      "Fetching page 25 for subject Computer+Science, count: 24\n",
      "Fetching page 26 for subject Computer+Science, count: 24\n",
      "Fetching page 27 for subject Computer+Science, count: 24\n",
      "Fetching page 28 for subject Computer+Science, count: 24\n",
      "Fetching page 29 for subject Computer+Science, count: 24\n",
      "Fetching page 30 for subject Computer+Science, count: 24\n",
      "Fetching page 31 for subject Computer+Science, count: 24\n",
      "Fetching page 32 for subject Computer+Science, count: 24\n",
      "Fetching page 33 for subject Computer+Science, count: 24\n",
      "Fetching page 34 for subject Computer+Science, count: 24\n",
      "Fetching page 35 for subject Computer+Science, count: 24\n",
      "Fetching page 36 for subject Computer+Science, count: 24\n",
      "Fetching page 37 for subject Computer+Science, count: 24\n",
      "Fetching page 38 for subject Computer+Science, count: 24\n",
      "Fetching page 39 for subject Computer+Science, count: 24\n",
      "Fetching page 40 for subject Computer+Science, count: 24\n",
      "Fetching page 41 for subject Computer+Science, count: 24\n",
      "Fetching page 42 for subject Computer+Science, count: 16\n",
      "===> Total courses fetched for Computer+Science: 1000\n",
      "Fetching Data+Analysis+%26+Statistics\n",
      "Last page number for subject Data+Analysis+%26+Statistics: 19\n",
      "Fetching page 1 for subject Data+Analysis+%26+Statistics, count: 24\n",
      "Fetching page 2 for subject Data+Analysis+%26+Statistics, count: 24\n",
      "Fetching page 3 for subject Data+Analysis+%26+Statistics, count: 24\n",
      "Fetching page 4 for subject Data+Analysis+%26+Statistics, count: 24\n",
      "Fetching page 5 for subject Data+Analysis+%26+Statistics, count: 24\n",
      "Fetching page 6 for subject Data+Analysis+%26+Statistics, count: 24\n",
      "Fetching page 7 for subject Data+Analysis+%26+Statistics, count: 24\n",
      "Fetching page 8 for subject Data+Analysis+%26+Statistics, count: 24\n",
      "Fetching page 9 for subject Data+Analysis+%26+Statistics, count: 24\n",
      "Fetching page 10 for subject Data+Analysis+%26+Statistics, count: 24\n",
      "Fetching page 11 for subject Data+Analysis+%26+Statistics, count: 24\n",
      "Fetching page 12 for subject Data+Analysis+%26+Statistics, count: 24\n",
      "Fetching page 13 for subject Data+Analysis+%26+Statistics, count: 24\n",
      "Fetching page 14 for subject Data+Analysis+%26+Statistics, count: 24\n",
      "Fetching page 15 for subject Data+Analysis+%26+Statistics, count: 24\n",
      "Fetching page 16 for subject Data+Analysis+%26+Statistics, count: 24\n",
      "Fetching page 17 for subject Data+Analysis+%26+Statistics, count: 24\n",
      "Fetching page 18 for subject Data+Analysis+%26+Statistics, count: 24\n",
      "Fetching page 19 for subject Data+Analysis+%26+Statistics, count: 13\n",
      "===> Total courses fetched for Data+Analysis+%26+Statistics: 445\n",
      "Fetching Design\n",
      "Last page number for subject Design: 6\n",
      "Fetching page 1 for subject Design, count: 24\n",
      "Fetching page 2 for subject Design, count: 24\n",
      "Fetching page 3 for subject Design, count: 24\n",
      "Fetching page 4 for subject Design, count: 24\n",
      "Fetching page 5 for subject Design, count: 24\n",
      "Fetching page 6 for subject Design, count: 20\n",
      "===> Total courses fetched for Design: 140\n",
      "Fetching Economics+%26+Finance\n",
      "Last page number for subject Economics+%26+Finance: 22\n",
      "Fetching page 1 for subject Economics+%26+Finance, count: 24\n",
      "Fetching page 2 for subject Economics+%26+Finance, count: 24\n",
      "Fetching page 3 for subject Economics+%26+Finance, count: 24\n",
      "Fetching page 4 for subject Economics+%26+Finance, count: 24\n",
      "Fetching page 5 for subject Economics+%26+Finance, count: 24\n",
      "Fetching page 6 for subject Economics+%26+Finance, count: 24\n",
      "Fetching page 7 for subject Economics+%26+Finance, count: 24\n",
      "Fetching page 8 for subject Economics+%26+Finance, count: 24\n",
      "Fetching page 9 for subject Economics+%26+Finance, count: 24\n",
      "Fetching page 10 for subject Economics+%26+Finance, count: 24\n",
      "Fetching page 11 for subject Economics+%26+Finance, count: 24\n",
      "Fetching page 12 for subject Economics+%26+Finance, count: 24\n",
      "Fetching page 13 for subject Economics+%26+Finance, count: 24\n",
      "Fetching page 14 for subject Economics+%26+Finance, count: 24\n",
      "Fetching page 15 for subject Economics+%26+Finance, count: 24\n",
      "Fetching page 16 for subject Economics+%26+Finance, count: 24\n",
      "Fetching page 17 for subject Economics+%26+Finance, count: 24\n",
      "Fetching page 18 for subject Economics+%26+Finance, count: 24\n",
      "Fetching page 19 for subject Economics+%26+Finance, count: 24\n",
      "Fetching page 20 for subject Economics+%26+Finance, count: 24\n",
      "Fetching page 21 for subject Economics+%26+Finance, count: 24\n",
      "Fetching page 22 for subject Economics+%26+Finance, count: 14\n",
      "===> Total courses fetched for Economics+%26+Finance: 518\n",
      "Fetching Education+%26+Teacher+Training\n",
      "Last page number for subject Education+%26+Teacher+Training: 12\n",
      "Fetching page 1 for subject Education+%26+Teacher+Training, count: 24\n",
      "Fetching page 2 for subject Education+%26+Teacher+Training, count: 24\n",
      "Fetching page 3 for subject Education+%26+Teacher+Training, count: 24\n",
      "Fetching page 4 for subject Education+%26+Teacher+Training, count: 24\n",
      "Fetching page 5 for subject Education+%26+Teacher+Training, count: 24\n",
      "Fetching page 6 for subject Education+%26+Teacher+Training, count: 24\n",
      "Fetching page 7 for subject Education+%26+Teacher+Training, count: 24\n",
      "Fetching page 8 for subject Education+%26+Teacher+Training, count: 24\n",
      "Fetching page 9 for subject Education+%26+Teacher+Training, count: 24\n",
      "Fetching page 10 for subject Education+%26+Teacher+Training, count: 24\n",
      "Fetching page 11 for subject Education+%26+Teacher+Training, count: 24\n",
      "Fetching page 12 for subject Education+%26+Teacher+Training, count: 2\n",
      "===> Total courses fetched for Education+%26+Teacher+Training: 266\n",
      "Fetching Electronics\n",
      "Last page number for subject Electronics: 4\n",
      "Fetching page 1 for subject Electronics, count: 24\n",
      "Fetching page 2 for subject Electronics, count: 24\n",
      "Fetching page 3 for subject Electronics, count: 24\n",
      "Fetching page 4 for subject Electronics, count: 18\n",
      "===> Total courses fetched for Electronics: 90\n",
      "Fetching Energy+%26+Earth+Sciences\n",
      "Last page number for subject Energy+%26+Earth+Sciences: 6\n",
      "Fetching page 1 for subject Energy+%26+Earth+Sciences, count: 24\n",
      "Fetching page 2 for subject Energy+%26+Earth+Sciences, count: 24\n",
      "Fetching page 3 for subject Energy+%26+Earth+Sciences, count: 24\n",
      "Fetching page 4 for subject Energy+%26+Earth+Sciences, count: 24\n",
      "Fetching page 5 for subject Energy+%26+Earth+Sciences, count: 24\n",
      "Fetching page 6 for subject Energy+%26+Earth+Sciences, count: 24\n",
      "===> Total courses fetched for Energy+%26+Earth+Sciences: 144\n",
      "Fetching Engineering\n",
      "Last page number for subject Engineering: 29\n",
      "Fetching page 1 for subject Engineering, count: 24\n",
      "Fetching page 2 for subject Engineering, count: 24\n",
      "Fetching page 3 for subject Engineering, count: 24\n",
      "Fetching page 4 for subject Engineering, count: 24\n",
      "Fetching page 5 for subject Engineering, count: 24\n",
      "Fetching page 6 for subject Engineering, count: 24\n",
      "Fetching page 7 for subject Engineering, count: 24\n",
      "Fetching page 8 for subject Engineering, count: 24\n",
      "Fetching page 9 for subject Engineering, count: 24\n",
      "Fetching page 10 for subject Engineering, count: 24\n",
      "Fetching page 11 for subject Engineering, count: 24\n",
      "Fetching page 12 for subject Engineering, count: 24\n",
      "Fetching page 13 for subject Engineering, count: 24\n",
      "Fetching page 14 for subject Engineering, count: 24\n",
      "Fetching page 15 for subject Engineering, count: 24\n",
      "Fetching page 16 for subject Engineering, count: 24\n",
      "Fetching page 17 for subject Engineering, count: 24\n",
      "Fetching page 18 for subject Engineering, count: 24\n",
      "Fetching page 19 for subject Engineering, count: 24\n",
      "Fetching page 20 for subject Engineering, count: 24\n",
      "Fetching page 21 for subject Engineering, count: 24\n",
      "Fetching page 22 for subject Engineering, count: 24\n",
      "Fetching page 23 for subject Engineering, count: 24\n",
      "Fetching page 24 for subject Engineering, count: 24\n",
      "Fetching page 25 for subject Engineering, count: 24\n",
      "Fetching page 26 for subject Engineering, count: 24\n",
      "Fetching page 27 for subject Engineering, count: 24\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: \nStacktrace:\n#0 0x5601fc9866aa <unknown>\n#1 0x5601fc6690dc <unknown>\n#2 0x5601fc6b5931 <unknown>\n#3 0x5601fc6b5a21 <unknown>\n#4 0x5601fc6fa234 <unknown>\n#5 0x5601fc6d889d <unknown>\n#6 0x5601fc6f75c3 <unknown>\n#7 0x5601fc6d8613 <unknown>\n#8 0x5601fc6a84f7 <unknown>\n#9 0x5601fc6a8e4e <unknown>\n#10 0x5601fc94c87b <unknown>\n#11 0x5601fc950921 <unknown>\n#12 0x5601fc93836e <unknown>\n#13 0x5601fc951482 <unknown>\n#14 0x5601fc91cccf <unknown>\n#15 0x5601fc9760a8 <unknown>\n#16 0x5601fc976280 <unknown>\n#17 0x5601fc9857dc <unknown>\n#18 0x7fe5ce253ac3 <unknown>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Loop through each page\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, last_page_number \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 19\u001b[0m     course_data \u001b[38;5;241m=\u001b[39m \u001b[43mget_course_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for subject \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubject\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, count: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(course_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m     subject_course\u001b[38;5;241m.\u001b[39mextend(course_data)\n",
      "Cell \u001b[0;32mIn[6], line 19\u001b[0m, in \u001b[0;36mget_course_data\u001b[0;34m(driver, subject, page)\u001b[0m\n\u001b[1;32m     17\u001b[0m course_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.edx.org\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m href\n\u001b[1;32m     18\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(course_url)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mwait\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpresence_of_element_located\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLASS_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcourse-header\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     20\u001b[0m course_soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(driver\u001b[38;5;241m.\u001b[39mpage_source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Extract course details\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/selenium/webdriver/support/wait.py:105\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m>\u001b[39m end_time:\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[0;31mTimeoutException\u001b[0m: Message: \nStacktrace:\n#0 0x5601fc9866aa <unknown>\n#1 0x5601fc6690dc <unknown>\n#2 0x5601fc6b5931 <unknown>\n#3 0x5601fc6b5a21 <unknown>\n#4 0x5601fc6fa234 <unknown>\n#5 0x5601fc6d889d <unknown>\n#6 0x5601fc6f75c3 <unknown>\n#7 0x5601fc6d8613 <unknown>\n#8 0x5601fc6a84f7 <unknown>\n#9 0x5601fc6a8e4e <unknown>\n#10 0x5601fc94c87b <unknown>\n#11 0x5601fc950921 <unknown>\n#12 0x5601fc93836e <unknown>\n#13 0x5601fc951482 <unknown>\n#14 0x5601fc91cccf <unknown>\n#15 0x5601fc9760a8 <unknown>\n#16 0x5601fc976280 <unknown>\n#17 0x5601fc9857dc <unknown>\n#18 0x7fe5ce253ac3 <unknown>\n"
     ]
    }
   ],
   "source": [
    "all_course_data = []\n",
    "\n",
    "# Loop through each subject\n",
    "for subject in subjects:\n",
    "    subject_course = []\n",
    "    \n",
    "    print(f\"Fetching {subject}\")\n",
    "\n",
    "    url = f\"https://www.edx.org/search?tab=course&page=1&subject={subject}\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'search-results-container')))\n",
    "    last_page_number = get_last_page_number(driver)\n",
    "\n",
    "    print(f\"Last page number for subject {subject}: {last_page_number}\")\n",
    "\n",
    "    # Loop through each page\n",
    "    for page in range(1, last_page_number + 1):\n",
    "        course_data = get_course_data(driver, subject, page)\n",
    "        print(f\"Fetching page {page} for subject {subject}, count: {len(course_data)}\")\n",
    "        subject_course.extend(course_data)\n",
    "        all_course_data.extend(course_data)\n",
    "    \n",
    "    print(f'===> Total courses fetched for {subject}: {len(subject_course)}')\n",
    "    \n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d19f1e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5254"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_course_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494913ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## Debug page 7 art and culture\n",
    "# url = \"https://www.edx.org/learn/architecture/harvard-university-the-architectural-imagination?index=product&queryID=04a3bf35c76e5138d31121e13db98a32&position=1&results_level=second-level-results&term=&objectID=course-8c411679-4105-4de9-8a4c-9c5b3f4a33a6&campaign=The+Architectural+Imagination&source=edX&product_category=course&placement_url=https%3A%2F%2Fwww.edx.org%2Fsearch\"\n",
    "\n",
    "# driver.get(url)\n",
    "# wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'course-header'))) \n",
    "# time.sleep(1.2) \n",
    "# course_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# # Extract course details\n",
    "# title = course_soup.find('div', class_='course-header').find('h1').text.strip()\n",
    "# print(title)\n",
    "\n",
    "\n",
    "# # Extract institution, subject, level, and language information\n",
    "# info_elements = course_soup.find('div', class_='course-main container-mw-sm container-fluid').find('ul', class_='mb-0 pl-3 ml-1').find_all('li')\n",
    "\n",
    "# #Sometime a some time p \n",
    "# institution_elem = info_elements[0].find('a') or info_elements[0].find('p')\n",
    "\n",
    "# institution = institution_elem.text.strip() if institution_elem else None\n",
    "# subject = info_elements[1].find('a').text.strip() if len(info_elements) > 1 else None\n",
    "# level = info_elements[2].text.strip().replace('Level: ', '') if len(info_elements) > 2 else None\n",
    "\n",
    "# language_element = course_soup.find('div', class_='course-main container-mw-sm container-fluid').find_all('div', class_='col-12 col-md-6')[1].find('ul', class_='pl-3 ml-1 mb-0').find_all('li')[0]\n",
    "# language = language_element.text.strip().replace('Language: ', '') if language_element else None\n",
    "\n",
    "\n",
    "# print(institution)\n",
    "# print(subject)\n",
    "# print(level)\n",
    "# print(language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4e0688e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping complete. Data saved to edx_courses.csv\n"
     ]
    }
   ],
   "source": [
    "# Save data to a DataFrame and CSV\n",
    "df = pd.DataFrame(all_course_data)\n",
    "df.to_csv('edx_courses.csv', index=False)\n",
    "\n",
    "print(\"Scraping complete. Data saved to edx_courses.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fb6da0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5254\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>sub_info</th>\n",
       "      <th>rating</th>\n",
       "      <th>subject</th>\n",
       "      <th>level</th>\n",
       "      <th>language</th>\n",
       "      <th>institution</th>\n",
       "      <th>about</th>\n",
       "      <th>what_you_will_learn</th>\n",
       "      <th>syllabus</th>\n",
       "      <th>image_url</th>\n",
       "      <th>course_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HarvardX: The Architectural Imagination</td>\n",
       "      <td>Learn fundamental principles of architecture —...</td>\n",
       "      <td>4.7 stars</td>\n",
       "      <td>Architecture</td>\n",
       "      <td>Introductory</td>\n",
       "      <td>English</td>\n",
       "      <td>HarvardX</td>\n",
       "      <td>Architecture engages a culture’s deepest socia...</td>\n",
       "      <td>How to read, analyze, and understand different...</td>\n",
       "      <td>Part I: Form and History Part II: The Technolo...</td>\n",
       "      <td>https://prod-discovery.edx-cdn.org/cdn-cgi/ima...</td>\n",
       "      <td>https://www.edx.org/learn/architecture/harvard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MITx: Sustainable Building Design</td>\n",
       "      <td>Learn and explore key scientific principles, t...</td>\n",
       "      <td>None</td>\n",
       "      <td>Architecture</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>English</td>\n",
       "      <td>MITx</td>\n",
       "      <td>Meeting growing global energy demand, while mi...</td>\n",
       "      <td>Understand the scientific principles underlyin...</td>\n",
       "      <td>Week 1 - Energy Use in Buildings Week 2 - Unde...</td>\n",
       "      <td>https://prod-discovery.edx-cdn.org/cdn-cgi/ima...</td>\n",
       "      <td>https://www.edx.org/learn/sustainable-developm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TokyoTechX: Japanese Architecture and Structur...</td>\n",
       "      <td>In this revised course, fundamental and modern...</td>\n",
       "      <td>4.2 stars</td>\n",
       "      <td>Architecture</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>English</td>\n",
       "      <td>TokyoTechX</td>\n",
       "      <td>In this revised course, in depth video lecture...</td>\n",
       "      <td>Evolution of seismic design concepts in Japan....</td>\n",
       "      <td>WEEK 1 : History of Japanese Structural Design...</td>\n",
       "      <td>https://prod-discovery.edx-cdn.org/cdn-cgi/ima...</td>\n",
       "      <td>https://www.edx.org/learn/architecture/tokyo-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NUS: Data Science for Construction, Architectu...</td>\n",
       "      <td>This course introduces data science skills tar...</td>\n",
       "      <td>4.6 stars</td>\n",
       "      <td>Data Analysis &amp; Statistics</td>\n",
       "      <td>Introductory</td>\n",
       "      <td>English</td>\n",
       "      <td>NUS</td>\n",
       "      <td>The building industry is exploding with data s...</td>\n",
       "      <td>Why data science is important for the built en...</td>\n",
       "      <td>Section 1: Introduction to Course and Python F...</td>\n",
       "      <td>https://prod-discovery.edx-cdn.org/cdn-cgi/ima...</td>\n",
       "      <td>https://www.edx.org/learn/data-science/the-nat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SDGAcademyX: Sustainable Cities</td>\n",
       "      <td>Learn how government, the private sector, and ...</td>\n",
       "      <td>4.7 stars</td>\n",
       "      <td>Environmental Studies</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>English</td>\n",
       "      <td>SDGAcademyX</td>\n",
       "      <td>Did you know that experts estimate an addition...</td>\n",
       "      <td>An overview of governance, land management, ut...</td>\n",
       "      <td>Module 1: The urban opportunity Module 2: What...</td>\n",
       "      <td>https://prod-discovery.edx-cdn.org/cdn-cgi/ima...</td>\n",
       "      <td>https://www.edx.org/learn/sustainability/sdg-a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0            HarvardX: The Architectural Imagination   \n",
       "1                  MITx: Sustainable Building Design   \n",
       "2  TokyoTechX: Japanese Architecture and Structur...   \n",
       "3  NUS: Data Science for Construction, Architectu...   \n",
       "4                    SDGAcademyX: Sustainable Cities   \n",
       "\n",
       "                                            sub_info     rating  \\\n",
       "0  Learn fundamental principles of architecture —...  4.7 stars   \n",
       "1  Learn and explore key scientific principles, t...       None   \n",
       "2  In this revised course, fundamental and modern...  4.2 stars   \n",
       "3  This course introduces data science skills tar...  4.6 stars   \n",
       "4  Learn how government, the private sector, and ...  4.7 stars   \n",
       "\n",
       "                      subject         level language  institution  \\\n",
       "0                Architecture  Introductory  English     HarvardX   \n",
       "1                Architecture  Intermediate  English         MITx   \n",
       "2                Architecture  Intermediate  English   TokyoTechX   \n",
       "3  Data Analysis & Statistics  Introductory  English          NUS   \n",
       "4       Environmental Studies  Intermediate  English  SDGAcademyX   \n",
       "\n",
       "                                               about  \\\n",
       "0  Architecture engages a culture’s deepest socia...   \n",
       "1  Meeting growing global energy demand, while mi...   \n",
       "2  In this revised course, in depth video lecture...   \n",
       "3  The building industry is exploding with data s...   \n",
       "4  Did you know that experts estimate an addition...   \n",
       "\n",
       "                                 what_you_will_learn  \\\n",
       "0  How to read, analyze, and understand different...   \n",
       "1  Understand the scientific principles underlyin...   \n",
       "2  Evolution of seismic design concepts in Japan....   \n",
       "3  Why data science is important for the built en...   \n",
       "4  An overview of governance, land management, ut...   \n",
       "\n",
       "                                            syllabus  \\\n",
       "0  Part I: Form and History Part II: The Technolo...   \n",
       "1  Week 1 - Energy Use in Buildings Week 2 - Unde...   \n",
       "2  WEEK 1 : History of Japanese Structural Design...   \n",
       "3  Section 1: Introduction to Course and Python F...   \n",
       "4  Module 1: The urban opportunity Module 2: What...   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://prod-discovery.edx-cdn.org/cdn-cgi/ima...   \n",
       "1  https://prod-discovery.edx-cdn.org/cdn-cgi/ima...   \n",
       "2  https://prod-discovery.edx-cdn.org/cdn-cgi/ima...   \n",
       "3  https://prod-discovery.edx-cdn.org/cdn-cgi/ima...   \n",
       "4  https://prod-discovery.edx-cdn.org/cdn-cgi/ima...   \n",
       "\n",
       "                                          course_url  \n",
       "0  https://www.edx.org/learn/architecture/harvard...  \n",
       "1  https://www.edx.org/learn/sustainable-developm...  \n",
       "2  https://www.edx.org/learn/architecture/tokyo-i...  \n",
       "3  https://www.edx.org/learn/data-science/the-nat...  \n",
       "4  https://www.edx.org/learn/sustainability/sdg-a...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a254d63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Architecture', 'Data Analysis & Statistics',\n",
       "       'Environmental Studies', 'Computer Science', 'Engineering',\n",
       "       'Humanities', 'Social Sciences', 'Business & Management',\n",
       "       'Energy & Earth Sciences', 'Art & Culture', 'Design', 'History',\n",
       "       'Language', 'Literature', 'Communication',\n",
       "       'Education & Teacher Training', 'Music', 'Food & Nutrition',\n",
       "       'Health & Safety', 'Medicine', 'Biology & Life Sciences', 'Math',\n",
       "       'Physics', 'Science', 'Chemistry', 'Philosophy & Ethics',\n",
       "       'Economics & Finance', 'Law', 'Ethics', 'Electronics'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subject'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e86703f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why data science is important for the built environment. Why building industry professionals should learn how to code. A jump start in the Python Programming Language. Overview of the Pandas data analysis library. Guidance in the loading, processing, and merging of data. Visualization of data from buildings. Basic machine learning concepts applied to building data. Examples of parametric analysis for the integrated design process. Examples of how to process time-series data from IoT sensors. Examples of analysis of thermal comfort data from occupants. Numerous starting points for using data science in other building-related tasks'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[3]['what_you_will_learn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b999ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (NGC 24.01 / TensorFlow 2.14) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
